{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import utm\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "from utils.from_latlon import from_latlon\n",
    "from utils.preprocessing import preprocess\n",
    "from utils.postprocessing import postprocess_data, location_averaging, calculate_error\n",
    "\n",
    "seed = 38 # Seed for train/val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify data paths\n",
    "train_data = 'Example_data\\Output\\Train_test_data\\Training_Tag_GPS_locations.xlsx'\n",
    "test_data = 'Example_data\\Output\\Train_test_data\\Testing_Tag_GPS_locations.xlsx'\n",
    "radio_tower_xy_path = 'Example_data\\Input\\Radio_tower_locations\\RTEastNorth.xlsx'\n",
    "\n",
    "# Variable parameters\n",
    "freq = '3min' # Frequency of data\n",
    "\n",
    "# Fixed parameters\n",
    "routine = 'training'\n",
    "data_type = ['Simulated BTFS'] # Simulation or Live BTF, or could do both 'Simulated BTFS', 'BTFS'\n",
    "dimensions = ['xOffset', 'yOffset']\n",
    "# predictors = ['ant1_mean', 'ant2_mean', 'ant3_mean', 'ant4_mean', 'ant1_count', 'ant2_count', 'ant3_count', 'ant4_count', 'ant1_std', 'ant2_std', 'ant3_std', 'ant4_std', 'mean_std', 'total_count']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sim_data(sim_data, data_type, freq, tower_locs, routine):\n",
    "    # Get data\n",
    "    sim_dat_filt = sim_data[sim_data['Data_type'].isin(data_type)]\n",
    "    \n",
    "    sim_dat_filt, predictors = preprocess(sim_dat_filt, freq, routine)\n",
    "     \n",
    "    # Calculate easting and northing from lat long\n",
    "    sim_dat_filt['easting'], sim_dat_filt['northing'], sim_dat_filt['zone_num'], sim_dat_filt['zone_letter'] = from_latlon(sim_dat_filt['POINT_Y'].values, sim_dat_filt['POINT_X'].values)\n",
    "\n",
    "    # Create a dictionary of the coordinates of the towers\n",
    "    offset_dict = tower_locs.set_index('TowerID').to_dict()\n",
    "    point_x = offset_dict['POINT_X']\n",
    "    point_y = offset_dict['POINT_Y']\n",
    "    tower_g = offset_dict['tower_group']\n",
    "\n",
    "    # Standardise the coordinates so that the tower location == 0 on both the x and y axes.\n",
    "    sim_dat_filt['xOffset'] = sim_dat_filt['easting'] - sim_dat_filt['TowerID'].map(point_x).fillna(0)\n",
    "    sim_dat_filt['yOffset'] = sim_dat_filt['northing'] - sim_dat_filt['TowerID'].map(point_y).fillna(0)\n",
    "    \n",
    "    # Add the model group\n",
    "    sim_dat_filt['tower_group'] = sim_dat_filt['TowerID'].map(tower_g).fillna(0)\n",
    "\n",
    "    return sim_dat_filt, predictors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training data\n",
    "train_data = pd.read_excel(train_data)\n",
    "train_data['DateAndTime'] = pd.to_datetime(train_data['DateAndTime'])\n",
    "\n",
    "# Get testing data\n",
    "test_data = pd.read_excel(test_data)\n",
    "test_data['DateAndTime'] = pd.to_datetime(test_data['DateAndTime'])\n",
    "\n",
    "# Get tower locations\n",
    "tower_locs = pd.read_excel(radio_tower_xy_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filtered_df_test = train_data_preproc[train_data_preproc['Data_type'] == 'Simulated BTFS']\n",
    "# filtered_df_test = train_data_preproc[(train_data_preproc['Data_type'] == 'Simulated BTFS') & (train_data_preproc['Tag_type'] == 'Nanotag')]\n",
    "# filtered_df_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation minimum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32mc:\\Users\\John\\Documents\\GitHub\\ml4rt\\train_model_multi_groups.ipynb Cell 6\u001b[0m line \u001b[0;36m3\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/John/Documents/GitHub/ml4rt/train_model_multi_groups.ipynb#W5sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39m# Preprocess the training and testing data\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/John/Documents/GitHub/ml4rt/train_model_multi_groups.ipynb#W5sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m train_data_preproc, predictors_train \u001b[39m=\u001b[39m preprocess_sim_data(train_data, data_type, freq, tower_locs, routine)\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/John/Documents/GitHub/ml4rt/train_model_multi_groups.ipynb#W5sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m test_data_preproc, predictors_test \u001b[39m=\u001b[39m preprocess_sim_data(test_data, data_type, freq, tower_locs, routine)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/John/Documents/GitHub/ml4rt/train_model_multi_groups.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m train_data_preproc \u001b[39m=\u001b[39m train_data_preproc[train_data_preproc[\u001b[39m'\u001b[39m\u001b[39mTag_type\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m==\u001b[39m \u001b[39m'\u001b[39m\u001b[39mNanotag\u001b[39m\u001b[39m'\u001b[39m]\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/John/Documents/GitHub/ml4rt/train_model_multi_groups.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m tower_groups \u001b[39m=\u001b[39m tower_locs[\u001b[39m'\u001b[39m\u001b[39mtower_group\u001b[39m\u001b[39m'\u001b[39m]\u001b[39m.\u001b[39munique()\n",
      "\u001b[1;32mc:\\Users\\John\\Documents\\GitHub\\ml4rt\\train_model_multi_groups.ipynb Cell 6\u001b[0m line \u001b[0;36m8\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/John/Documents/GitHub/ml4rt/train_model_multi_groups.ipynb#W5sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m sim_dat_filt, predictors \u001b[39m=\u001b[39m preprocess(sim_dat_filt, freq, routine)\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/John/Documents/GitHub/ml4rt/train_model_multi_groups.ipynb#W5sZmlsZQ%3D%3D?line=6'>7</a>\u001b[0m \u001b[39m# Calculate easting and northing from lat long\u001b[39;00m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/John/Documents/GitHub/ml4rt/train_model_multi_groups.ipynb#W5sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m sim_dat_filt[\u001b[39m'\u001b[39m\u001b[39measting\u001b[39m\u001b[39m'\u001b[39m], sim_dat_filt[\u001b[39m'\u001b[39m\u001b[39mnorthing\u001b[39m\u001b[39m'\u001b[39m], sim_dat_filt[\u001b[39m'\u001b[39m\u001b[39mzone_num\u001b[39m\u001b[39m'\u001b[39m], sim_dat_filt[\u001b[39m'\u001b[39m\u001b[39mzone_letter\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m from_latlon(sim_dat_filt[\u001b[39m'\u001b[39;49m\u001b[39mPOINT_Y\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mvalues, sim_dat_filt[\u001b[39m'\u001b[39;49m\u001b[39mPOINT_X\u001b[39;49m\u001b[39m'\u001b[39;49m]\u001b[39m.\u001b[39;49mvalues)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/John/Documents/GitHub/ml4rt/train_model_multi_groups.ipynb#W5sZmlsZQ%3D%3D?line=9'>10</a>\u001b[0m \u001b[39m# Create a dictionary of the coordinates of the towers\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/John/Documents/GitHub/ml4rt/train_model_multi_groups.ipynb#W5sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m offset_dict \u001b[39m=\u001b[39m tower_locs\u001b[39m.\u001b[39mset_index(\u001b[39m'\u001b[39m\u001b[39mTowerID\u001b[39m\u001b[39m'\u001b[39m)\u001b[39m.\u001b[39mto_dict()\n",
      "File \u001b[1;32mc:\\Users\\John\\Documents\\GitHub\\ml4rt\\utils\\from_latlon.py:5\u001b[0m, in \u001b[0;36mfrom_latlon\u001b[1;34m(lat, lon)\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_latlon\u001b[39m(lat, lon):\n\u001b[1;32m----> 5\u001b[0m     easting, northing, zone_num, zone_letter \u001b[39m=\u001b[39m utm\u001b[39m.\u001b[39;49mfrom_latlon(lat, lon)\n\u001b[0;32m      6\u001b[0m     \u001b[39mreturn\u001b[39;00m easting, northing, zone_num, zone_letter\n",
      "File \u001b[1;32mc:\\Users\\John\\Documents\\GitHub\\ml4rt\\.venv\\lib\\site-packages\\utm\\conversion.py:228\u001b[0m, in \u001b[0;36mfrom_latlon\u001b[1;34m(latitude, longitude, force_zone_number, force_zone_letter)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfrom_latlon\u001b[39m(latitude, longitude, force_zone_number\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, force_zone_letter\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[0;32m    190\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"This function converts Latitude and Longitude to UTM coordinate\u001b[39;00m\n\u001b[0;32m    191\u001b[0m \n\u001b[0;32m    192\u001b[0m \u001b[39m        Parameters\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    226\u001b[0m \u001b[39m       .. _[1]: http://www.jaworski.ca/utmzones.htm\u001b[39;00m\n\u001b[0;32m    227\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m--> 228\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m in_bounds(latitude, \u001b[39m-\u001b[39;49m\u001b[39m80.0\u001b[39;49m, \u001b[39m84.0\u001b[39;49m):\n\u001b[0;32m    229\u001b[0m         \u001b[39mraise\u001b[39;00m OutOfRangeError(\u001b[39m'\u001b[39m\u001b[39mlatitude out of range (must be between 80 deg S and 84 deg N)\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m    230\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m in_bounds(longitude, \u001b[39m-\u001b[39m\u001b[39m180.0\u001b[39m, \u001b[39m180.0\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\John\\Documents\\GitHub\\ml4rt\\.venv\\lib\\site-packages\\utm\\conversion.py:49\u001b[0m, in \u001b[0;36min_bounds\u001b[1;34m(x, lower, upper, upper_strict)\u001b[0m\n\u001b[0;32m     47\u001b[0m     \u001b[39mreturn\u001b[39;00m lower \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m x \u001b[39m<\u001b[39m upper\n\u001b[0;32m     48\u001b[0m \u001b[39melif\u001b[39;00m use_numpy:\n\u001b[1;32m---> 49\u001b[0m     \u001b[39mreturn\u001b[39;00m lower \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m mathlib\u001b[39m.\u001b[39;49mmin(x) \u001b[39mand\u001b[39;00m mathlib\u001b[39m.\u001b[39mmax(x) \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m upper\n\u001b[0;32m     50\u001b[0m \u001b[39mreturn\u001b[39;00m lower \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m x \u001b[39m<\u001b[39m\u001b[39m=\u001b[39m upper\n",
      "File \u001b[1;32m<__array_function__ internals>:200\u001b[0m, in \u001b[0;36mamin\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\John\\Documents\\GitHub\\ml4rt\\.venv\\lib\\site-packages\\numpy\\core\\fromnumeric.py:2946\u001b[0m, in \u001b[0;36mamin\u001b[1;34m(a, axis, out, keepdims, initial, where)\u001b[0m\n\u001b[0;32m   2829\u001b[0m \u001b[39m@array_function_dispatch\u001b[39m(_amin_dispatcher)\n\u001b[0;32m   2830\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mamin\u001b[39m(a, axis\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, out\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m, keepdims\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue, initial\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue,\n\u001b[0;32m   2831\u001b[0m          where\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39m_NoValue):\n\u001b[0;32m   2832\u001b[0m \u001b[39m    \u001b[39m\u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   2833\u001b[0m \u001b[39m    Return the minimum of an array or minimum along an axis.\u001b[39;00m\n\u001b[0;32m   2834\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2944\u001b[0m \u001b[39m    6\u001b[39;00m\n\u001b[0;32m   2945\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 2946\u001b[0m     \u001b[39mreturn\u001b[39;00m _wrapreduction(a, np\u001b[39m.\u001b[39;49mminimum, \u001b[39m'\u001b[39;49m\u001b[39mmin\u001b[39;49m\u001b[39m'\u001b[39;49m, axis, \u001b[39mNone\u001b[39;49;00m, out,\n\u001b[0;32m   2947\u001b[0m                           keepdims\u001b[39m=\u001b[39;49mkeepdims, initial\u001b[39m=\u001b[39;49minitial, where\u001b[39m=\u001b[39;49mwhere)\n",
      "File \u001b[1;32mc:\\Users\\John\\Documents\\GitHub\\ml4rt\\.venv\\lib\\site-packages\\numpy\\core\\fromnumeric.py:86\u001b[0m, in \u001b[0;36m_wrapreduction\u001b[1;34m(obj, ufunc, method, axis, dtype, out, **kwargs)\u001b[0m\n\u001b[0;32m     83\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     84\u001b[0m             \u001b[39mreturn\u001b[39;00m reduction(axis\u001b[39m=\u001b[39maxis, out\u001b[39m=\u001b[39mout, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpasskwargs)\n\u001b[1;32m---> 86\u001b[0m \u001b[39mreturn\u001b[39;00m ufunc\u001b[39m.\u001b[39mreduce(obj, axis, dtype, out, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mpasskwargs)\n",
      "\u001b[1;31mValueError\u001b[0m: zero-size array to reduction operation minimum which has no identity"
     ]
    }
   ],
   "source": [
    "# Preprocess the training and testing data\n",
    "train_data_preproc, predictors_train = preprocess_sim_data(train_data, data_type, freq, tower_locs, routine)\n",
    "test_data_preproc, predictors_test = preprocess_sim_data(test_data, data_type, freq, tower_locs, routine)\n",
    "\n",
    "train_data_preproc = train_data_preproc[train_data_preproc['Tag_type'] == 'Nanotag']\n",
    "\n",
    "tower_groups = tower_locs['tower_group'].unique()\n",
    "\n",
    "# Initialise h2o\n",
    "h2o.init(nthreads = 2)\n",
    "\n",
    "# Train, save and test the models for each dimension for each model grouping\n",
    "for tower_group in tower_groups:\n",
    "    for dimension in dimensions:\n",
    "        print(f\"Training model for {dimension} in tower group {tower_group}\")\n",
    "        # Train the model\n",
    "        variables = predictors_train + [dimension]\n",
    "        training_input = train_data_preproc[train_data_preproc['tower_group'] == tower_group]\n",
    "        training_input = training_input[variables]\n",
    "        train = h2o.H2OFrame(training_input)\n",
    "        aml = H2OAutoML(max_models=20, seed=seed, stopping_metric='MAE', sort_metric='MAE')\n",
    "        aml.train(x=predictors_train, y=dimension, training_frame=train)\n",
    "        # print(aml.leaderboard)\n",
    "\n",
    "        # Save the leader model\n",
    "        h2o.save_model(aml.leader, path = f\"Example_data\\Output\\Trained_models\\{dimension}_tower_group_{tower_group}\", force=True)\n",
    "\n",
    "        # Make predictions on the test data\n",
    "        test_input = test_data_preproc[test_data_preproc['tower_group'] == tower_group]\n",
    "        test = h2o.H2OFrame(test_input)\n",
    "        preds = aml.leader.predict(test)\n",
    "\n",
    "        # Save predictions to a new column in the test dataframe\n",
    "        pred_column_name = f\"{dimension}_pred\"\n",
    "        test_data_preproc.loc[test_data_preproc['tower_group'] == tower_group, pred_column_name] = preds.as_data_frame().values\n",
    "\n",
    "# Stop h2o\n",
    "h2o.cluster().shutdown()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test_predictions = postprocess_data(test_data_preproc, tower_locs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean error (+/-SE) = 292.963210021216 (+/- 19.903302922135218)\n"
     ]
    }
   ],
   "source": [
    "# Post process the test predictions to calculate location from the radio tower locations\n",
    "test_predictions_tower = postprocess_data(test_data_preproc, tower_locs)\n",
    "\n",
    "# Location averaging functions\n",
    "test_location_estimates = location_averaging(test_predictions_tower)\n",
    "test_location_estimates = calculate_error(test_location_estimates)\n",
    "\n",
    "# Calculate the mean absolute error of UTM_predictions['distance'] and the standard error\n",
    "mean_error = np.mean(test_location_estimates['error_m'])\n",
    "std_error = stats.sem(test_location_estimates['error_m'])\n",
    "\n",
    "print(f'Mean error (+/-SE) = {mean_error} (+/- {std_error})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_predictions_tower.to_excel(\"test_tower_predictions.xlsx\", index=False)\n",
    "test_location_estimates.to_excel(\"UTM_predictions.xlsx\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted_df = test_location_estimates.sort_values(by='error_m', ascending=False)\n",
    "# sorted_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sorted_df.to_excel(\"sorted_df.xlsx\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c9c44150708f88dcc61b6a40c517040b165081f9891458623fe805b4ae9321d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
