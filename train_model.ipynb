{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import utm\n",
    "import os\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import h2o\n",
    "from h2o.automl import H2OAutoML\n",
    "import tkinter as tk\n",
    "from tkinter import filedialog\n",
    "from tkinter.simpledialog import askstring\n",
    "from utils.from_latlon import from_latlon\n",
    "from utils.preprocessing import preprocess\n",
    "from utils.postprocessing import postprocess_data, location_averaging, calculate_error\n",
    "\n",
    "seed = 38 # randomly generated for ML process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frequency: 3min\n"
     ]
    }
   ],
   "source": [
    "# User input of data paths and temporal resolution\n",
    "\n",
    "# Initialize Tkinter\n",
    "root = tk.Tk()\n",
    "root.withdraw()\n",
    "\n",
    "# Ask the user to select the train data file\n",
    "train_data = filedialog.askopenfilename(\n",
    "    title=\"Select training data\",\n",
    "    filetypes=[(\"Excel files\", \"*.xlsx\")]\n",
    ")\n",
    "\n",
    "# Ask the user to select the test data file\n",
    "test_data = filedialog.askopenfilename(\n",
    "    title=\"Select testing data\",\n",
    "    filetypes=[(\"Excel files\", \"*.xlsx\")]\n",
    ")\n",
    "\n",
    "# Ask the user to select the radio tower XY data file\n",
    "radio_tower_xy_path = filedialog.askopenfilename(\n",
    "    title=\"Select radio tower location data\",\n",
    "    filetypes=[(\"Excel files\", \"*.xlsx\")]\n",
    ")\n",
    "\n",
    "# Ask the user to select the model save path\n",
    "model_save_path = filedialog.askdirectory(\n",
    "    title=\"Select model save path\"\n",
    ")\n",
    "\n",
    "# Function to get minutes from user\n",
    "def get_minutes():\n",
    "    while True:\n",
    "        minutes = askstring(\"Time (in minutes) to compile location data (t)\", \"Enter time period (t) in minutes (must be an integer):\")\n",
    "        if minutes and minutes.isdigit():\n",
    "            return minutes\n",
    "        messagebox.showerror(\"Error\", \"Invalid input. Please enter a number.\")\n",
    "\n",
    "# Prompt the user and get the validated input\n",
    "minutes = get_minutes()\n",
    "\n",
    "# Append the input number to 'min'\n",
    "freq = minutes + 'min'\n",
    "\n",
    "# Print freq to verify (optional)\n",
    "print(\"Frequency:\", freq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify data paths\n",
    "train_data = 'SBTF_data/input_data/train_test_data/train_data.xlsx'\n",
    "test_data = 'SBTF_data/input_data/train_test_data/test_data.xlsx'\n",
    "radio_tower_xy_path = 'SBTF_data/input_data/radio_tower_locations/RTEastNorth_1group.xlsx'\n",
    "model_save_path = 'SBTF_data/ml4rt_output/trained_models'\n",
    "\n",
    "# Variable parameters\n",
    "freq = '3min' # Frequency of data\n",
    "\n",
    "# Fixed parameters\n",
    "routine = 'training'\n",
    "dimensions = ['xOffset', 'yOffset']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_sim_data(sim_data, freq, tower_locs, routine):\n",
    "   \n",
    "    sim_dat_filt, predictors = preprocess(sim_data, freq, routine)\n",
    "     \n",
    "    # Calculate easting and northing from lat long\n",
    "    sim_dat_filt['easting'], sim_dat_filt['northing'], sim_dat_filt['zone_num'], sim_dat_filt['zone_letter'] = from_latlon(sim_dat_filt['POINT_Y'].values, sim_dat_filt['POINT_X'].values)\n",
    "\n",
    "    # Create a dictionary of the coordinates of the towers\n",
    "    offset_dict = tower_locs.set_index('TowerID').to_dict()\n",
    "    point_x = offset_dict['POINT_X']\n",
    "    point_y = offset_dict['POINT_Y']\n",
    "    tower_g = offset_dict['tower_group']\n",
    "\n",
    "    # Standardise the coordinates so that the tower location == 0 on both the x and y axes.\n",
    "    sim_dat_filt['xOffset'] = sim_dat_filt['easting'] - sim_dat_filt['TowerID'].map(point_x).fillna(0)\n",
    "    sim_dat_filt['yOffset'] = sim_dat_filt['northing'] - sim_dat_filt['TowerID'].map(point_y).fillna(0)\n",
    "    \n",
    "    # Add the model group\n",
    "    sim_dat_filt['tower_group'] = sim_dat_filt['TowerID'].map(tower_g).fillna(0)\n",
    "\n",
    "    return sim_dat_filt, predictors\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get training data\n",
    "train_data = pd.read_excel(train_data)\n",
    "train_data['DateAndTime'] = pd.to_datetime(train_data['DateAndTime'])\n",
    "\n",
    "# Get testing data\n",
    "test_data = pd.read_excel(test_data)\n",
    "test_data['DateAndTime'] = pd.to_datetime(test_data['DateAndTime'])\n",
    "\n",
    "# Get tower locations\n",
    "tower_locs = pd.read_excel(radio_tower_xy_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking whether there is an H2O instance running at http://localhost:54321."
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\JohnvanOsta\\Documents\\GitHub\\ml4rt\\utils\\preprocessing.py:10: FutureWarning: The provided callable <function std at 0x000002824CACB2E0> is currently using SeriesGroupBy.std. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"std\" instead.\n",
      "  .agg(['mean', 'count', np.std])\n",
      "c:\\Users\\JohnvanOsta\\Documents\\GitHub\\ml4rt\\utils\\preprocessing.py:10: FutureWarning: The provided callable <function std at 0x000002824CACB2E0> is currently using SeriesGroupBy.std. In a future version of pandas, the provided callable will be used directly. To keep current behavior pass the string \"std\" instead.\n",
      "  .agg(['mean', 'count', np.std])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ".... not found.\n",
      "Attempting to start a local H2O server...\n",
      "; Java HotSpot(TM) 64-Bit Server VM (build 17.0.10+11-LTS-240, mixed mode, sharing)\n",
      "  Starting server from C:\\Users\\JohnvanOsta\\Documents\\GitHub\\ml4rt\\.venv\\Lib\\site-packages\\h2o\\backend\\bin\\h2o.jar\n",
      "  Ice root: C:\\Users\\JOHNVA~1\\AppData\\Local\\Temp\\tmpzgezexy2\n",
      "  JVM stdout: C:\\Users\\JOHNVA~1\\AppData\\Local\\Temp\\tmpzgezexy2\\h2o_JohnvanOsta_started_from_python.out\n",
      "  JVM stderr: C:\\Users\\JOHNVA~1\\AppData\\Local\\Temp\\tmpzgezexy2\\h2o_JohnvanOsta_started_from_python.err\n",
      "  Server is running at http://127.0.0.1:54321\n",
      "Connecting to H2O server at http://127.0.0.1:54321 ... successful.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "<style>\n",
       "\n",
       "#h2o-table-2.h2o-container {\n",
       "  overflow-x: auto;\n",
       "}\n",
       "#h2o-table-2 .h2o-table {\n",
       "  /* width: 100%; */\n",
       "  margin-top: 1em;\n",
       "  margin-bottom: 1em;\n",
       "}\n",
       "#h2o-table-2 .h2o-table caption {\n",
       "  white-space: nowrap;\n",
       "  caption-side: top;\n",
       "  text-align: left;\n",
       "  /* margin-left: 1em; */\n",
       "  margin: 0;\n",
       "  font-size: larger;\n",
       "}\n",
       "#h2o-table-2 .h2o-table thead {\n",
       "  white-space: nowrap; \n",
       "  position: sticky;\n",
       "  top: 0;\n",
       "  box-shadow: 0 -1px inset;\n",
       "}\n",
       "#h2o-table-2 .h2o-table tbody {\n",
       "  overflow: auto;\n",
       "}\n",
       "#h2o-table-2 .h2o-table th,\n",
       "#h2o-table-2 .h2o-table td {\n",
       "  text-align: right;\n",
       "  /* border: 1px solid; */\n",
       "}\n",
       "#h2o-table-2 .h2o-table tr:nth-child(even) {\n",
       "  /* background: #F5F5F5 */\n",
       "}\n",
       "\n",
       "</style>      \n",
       "<div id=\"h2o-table-2\" class=\"h2o-container\">\n",
       "  <table class=\"h2o-table\">\n",
       "    <caption></caption>\n",
       "    <thead></thead>\n",
       "    <tbody><tr><td>H2O_cluster_uptime:</td>\n",
       "<td>01 secs</td></tr>\n",
       "<tr><td>H2O_cluster_timezone:</td>\n",
       "<td>Australia/Brisbane</td></tr>\n",
       "<tr><td>H2O_data_parsing_timezone:</td>\n",
       "<td>UTC</td></tr>\n",
       "<tr><td>H2O_cluster_version:</td>\n",
       "<td>3.44.0.3</td></tr>\n",
       "<tr><td>H2O_cluster_version_age:</td>\n",
       "<td>1 month and 3 days</td></tr>\n",
       "<tr><td>H2O_cluster_name:</td>\n",
       "<td>H2O_from_python_JohnvanOsta_wuajw5</td></tr>\n",
       "<tr><td>H2O_cluster_total_nodes:</td>\n",
       "<td>1</td></tr>\n",
       "<tr><td>H2O_cluster_free_memory:</td>\n",
       "<td>3.961 Gb</td></tr>\n",
       "<tr><td>H2O_cluster_total_cores:</td>\n",
       "<td>8</td></tr>\n",
       "<tr><td>H2O_cluster_allowed_cores:</td>\n",
       "<td>2</td></tr>\n",
       "<tr><td>H2O_cluster_status:</td>\n",
       "<td>locked, healthy</td></tr>\n",
       "<tr><td>H2O_connection_url:</td>\n",
       "<td>http://127.0.0.1:54321</td></tr>\n",
       "<tr><td>H2O_connection_proxy:</td>\n",
       "<td>{\"http\": null, \"https\": null}</td></tr>\n",
       "<tr><td>H2O_internal_security:</td>\n",
       "<td>False</td></tr>\n",
       "<tr><td>Python_version:</td>\n",
       "<td>3.11.7 final</td></tr></tbody>\n",
       "  </table>\n",
       "</div>\n"
      ],
      "text/plain": [
       "--------------------------  ----------------------------------\n",
       "H2O_cluster_uptime:         01 secs\n",
       "H2O_cluster_timezone:       Australia/Brisbane\n",
       "H2O_data_parsing_timezone:  UTC\n",
       "H2O_cluster_version:        3.44.0.3\n",
       "H2O_cluster_version_age:    1 month and 3 days\n",
       "H2O_cluster_name:           H2O_from_python_JohnvanOsta_wuajw5\n",
       "H2O_cluster_total_nodes:    1\n",
       "H2O_cluster_free_memory:    3.961 Gb\n",
       "H2O_cluster_total_cores:    8\n",
       "H2O_cluster_allowed_cores:  2\n",
       "H2O_cluster_status:         locked, healthy\n",
       "H2O_connection_url:         http://127.0.0.1:54321\n",
       "H2O_connection_proxy:       {\"http\": null, \"https\": null}\n",
       "H2O_internal_security:      False\n",
       "Python_version:             3.11.7 final\n",
       "--------------------------  ----------------------------------"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model for xOffset in tower group 1\n",
      "Parse progress: |████████████████████████████████████████████████████████████████| (done) 100%\n",
      "AutoML progress: |\n",
      "15:10:03.59: AutoML: XGBoost is not available; skipping it.\n",
      "\n",
      "████████████████████████████████████ (cancelled)\n"
     ]
    },
    {
     "ename": "H2OJobCancelled",
     "evalue": "Job<$03017f00000132d4ffffffff$_81f2edc73535bbacc40906b5bbf34bf5> was cancelled by the user.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mH2OJobCancelled\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[14], line 20\u001b[0m\n\u001b[0;32m     18\u001b[0m train \u001b[38;5;241m=\u001b[39m h2o\u001b[38;5;241m.\u001b[39mH2OFrame(training_input)\n\u001b[0;32m     19\u001b[0m aml \u001b[38;5;241m=\u001b[39m H2OAutoML(max_models\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m20\u001b[39m, seed\u001b[38;5;241m=\u001b[39mseed, stopping_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMAE\u001b[39m\u001b[38;5;124m'\u001b[39m, sort_metric\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMAE\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m---> 20\u001b[0m \u001b[43maml\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpredictors_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdimension\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtraining_frame\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     22\u001b[0m \u001b[38;5;66;03m# Save the leader model\u001b[39;00m\n\u001b[0;32m     23\u001b[0m h2o\u001b[38;5;241m.\u001b[39msave_model(aml\u001b[38;5;241m.\u001b[39mleader, path \u001b[38;5;241m=\u001b[39m model_save_path, force\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, filename\u001b[38;5;241m=\u001b[39m\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdimension\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_group_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtower_group\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_model\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\JohnvanOsta\\Documents\\GitHub\\ml4rt\\.venv\\Lib\\site-packages\\h2o\\automl\\_estimator.py:682\u001b[0m, in \u001b[0;36mH2OAutoML.train\u001b[1;34m(self, x, y, training_frame, fold_column, weights_column, validation_frame, leaderboard_frame, blending_frame)\u001b[0m\n\u001b[0;32m    680\u001b[0m poll_updates \u001b[38;5;241m=\u001b[39m ft\u001b[38;5;241m.\u001b[39mpartial(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_poll_training_updates, verbosity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_verbosity, state\u001b[38;5;241m=\u001b[39m{})\n\u001b[0;32m    681\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 682\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_job\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpoll_updates\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpoll_updates\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    683\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m    684\u001b[0m     poll_updates(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_job, \u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\JohnvanOsta\\Documents\\GitHub\\ml4rt\\.venv\\Lib\\site-packages\\h2o\\job.py:85\u001b[0m, in \u001b[0;36mH2OJob.poll\u001b[1;34m(self, poll_updates)\u001b[0m\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m# check if failed... and politely print relevant message\u001b[39;00m\n\u001b[0;32m     84\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCANCELLED\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m---> 85\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m H2OJobCancelled(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mJob<\u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m> was cancelled by the user.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m%\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob_key)\n\u001b[0;32m     86\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFAILED\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     87\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m (\u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob, \u001b[38;5;28mdict\u001b[39m)) \u001b[38;5;129;01mand\u001b[39;00m (\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstacktrace\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mjob)):\n",
      "\u001b[1;31mH2OJobCancelled\u001b[0m: Job<$03017f00000132d4ffffffff$_81f2edc73535bbacc40906b5bbf34bf5> was cancelled by the user."
     ]
    }
   ],
   "source": [
    "# Preprocess the training and testing data\n",
    "train_data_preproc, predictors_train = preprocess_sim_data(train_data, freq, tower_locs, routine)\n",
    "test_data_preproc, predictors_test = preprocess_sim_data(test_data, freq, tower_locs, routine)\n",
    "\n",
    "tower_groups = tower_locs['tower_group'].unique()\n",
    "\n",
    "# Initialise h2o\n",
    "h2o.init(nthreads = 2)\n",
    "\n",
    "# Train, save and test the models for each dimension for each model grouping\n",
    "for tower_group in tower_groups:\n",
    "    for dimension in dimensions:\n",
    "        print(f\"Training model for {dimension} in tower group {tower_group}\")\n",
    "        # Train the model\n",
    "        variables = predictors_train + [dimension]\n",
    "        training_input = train_data_preproc[train_data_preproc['tower_group'] == tower_group]\n",
    "        training_input = training_input[variables]\n",
    "        train = h2o.H2OFrame(training_input)\n",
    "        aml = H2OAutoML(max_models=20, seed=seed, stopping_metric='MAE', sort_metric='MAE')\n",
    "        aml.train(x=predictors_train, y=dimension, training_frame=train)\n",
    "\n",
    "        # Save the leader model\n",
    "        h2o.save_model(aml.leader, path = model_save_path, force=True, filename=f'{dimension}_group_{tower_group}_model')\n",
    "\n",
    "        # Make predictions on the test data\n",
    "        test_input = test_data_preproc[test_data_preproc['tower_group'] == tower_group]\n",
    "        test = h2o.H2OFrame(test_input)\n",
    "        preds = aml.leader.predict(test)\n",
    "\n",
    "        # Save predictions to a new column in the test dataframe\n",
    "        pred_column_name = f\"{dimension}_pred\"\n",
    "        test_data_preproc.loc[test_data_preproc['tower_group'] == tower_group, pred_column_name] = preds.as_data_frame().values\n",
    "\n",
    "# Stop h2o\n",
    "h2o.cluster().shutdown()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean error (+/-SE) = 256.1809716326903 (+/- 18.612738531367942)\n"
     ]
    }
   ],
   "source": [
    "# Post process the test predictions to calculate location from the radio tower locations\n",
    "test_predictions_tower = postprocess_data(test_data_preproc, tower_locs)\n",
    "\n",
    "# Location averaging functions\n",
    "test_location_estimates = location_averaging(test_predictions_tower)\n",
    "test_location_estimates = calculate_error(test_location_estimates)\n",
    "\n",
    "# Calculate the mean absolute error of UTM_predictions['distance'] and the standard error\n",
    "mean_error = np.mean(test_location_estimates['error_m'])\n",
    "std_error = stats.sem(test_location_estimates['error_m'])\n",
    "\n",
    "print(f'Mean error (+/-SE) = {mean_error} (+/- {std_error})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_location_estimates.to_excel(os.path.join(model_save_path, \"test_data_location_predictions.xlsx\"), index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "5c9c44150708f88dcc61b6a40c517040b165081f9891458623fe805b4ae9321d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
